{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "provenance": [],
      "name": "ARTIFEX_v7_Compositional_Safety.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# ğŸ“‘ PROJECT_README: ARTIFEX_LABS v7.0\n\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Tuesdaythe13th/artifex-v7/blob/main/ARTIFEX_v7_Compositional_Safety.ipynb)\n\n> **[Notebook Goal]**: Upgraded analysis of user feedback using 2026 SOTA techniques â€” BERTopic clustering, UMAP projection, entropy-based multi-agent compositional safety routing, and LLM-driven synthesis.\n>\n> **[Notebook Topic]**: ARTIFEX v7.0: Compositional Safety & Ethical AI Feedback Analysis\n>\n> **[Principal Investigator]**: Tuesday @ ARTIFEX Labs\n>\n> **[Version]**: 7.0.0 â€” Updated with 2025-2026 SOTA Research\n\n---\n\n### ğŸ“š Resource Links\n\n| Channel | Link |\n| --- | --- |\n| **Linktree** | [linktr.ee/artifexlabs](https://linktr.ee/artifexlabs) |\n| **Contact** | tuesday@artifexlabs |\n| **GitHub** | [github.com/tuesdaythe13th](https://github.com/tuesdaythe13th) |\n| **HuggingFace** | [huggingface.co/222tuesday](https://huggingface.co/222tuesday) |\n| **Google Scholar** | [scholar.google.com](https://scholar.google.com) |\n\n---\n\n### ğŸ§° Technical Stack (v7.0 â€” 2026 SOTA Upgrade)\n\n| Category | Libraries | Key Upgrade from v6.1 |\n| --- | --- | --- |\n| **Data Ingestion & Validation** | `pandas`, `pandera`, `google.colab` | Added `pandera` schema validation |\n| **Core Modeling & Embedding** | `bertopic`, `hdbscan`, `umap-learn`, `sentence-transformers` | **K-Means â†’ BERTopic + HDBSCAN** |\n| **Dimensionality Reduction** | `umap-learn` | **PCA â†’ UMAP** (non-linear, topology-preserving) |\n| **Compositional Safety** | Custom ARTIFEX Swarm v7 | **Added entropy-based LPP routing (AAMAS 2026)** |\n| **LLM Integration** | `openai` (Gemini 2.0 Flash compatible) | **Upgraded to Gemini 2.0 Flash** |\n| **Profiling & Visualization** | `ydata-profiling`, `plotly`, `matplotlib` | Added UMAP 3D interactive projection |\n| **Workflow & Provenance** | `tqdm`, `loguru`, `watermark`, `huggingface_hub` | Added HF Hub watermarking |\n\n---\n\n### ğŸ“– How-to-Cite\n\n```\nArtifex Labs (2026). ARTIFEX v7.0: Compositional Safety & Ethical AI Feedback Analysis.\nVersion 7.0. [Google Colab Notebook]. https://github.com/tuesdaythe13th/artifex-v7\n```\n\n---\n\n### âš ï¸ Legal Disclaimer\n\n> Â© 2026 Artifex Labs. This notebook and its contents are provided \"as-is\" for research and demonstration purposes only. The code may contain errors and is not intended for production use without independent verification. Redistribution or commercial use without the express written permission of Artifex Labs is strictly prohibited. By using this notebook, you agree to indemnify and hold harmless Artifex Labs and its affiliates from any and all claims, damages, losses, liabilities, costs, and expenses arising from your use of or inability to use this code.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# ğŸ—ï¸ ENV_INITIALIZATION: SOTA_COMPENDIUM_SETUP\n\nThis cell establishes the technical bedrock for **ARTIFEX v7.0**, installing a state-of-the-art compendium of libraries identified from 2025-2026 research. Key upgrades include `bertopic` for superior topic modeling over traditional K-Means, and `umap-learn` for more meaningful dimensionality reduction than PCA. All installations are performed quietly to maintain a clean initialization log, mitigating \"Colab Dependency Hell.\"\n\n### Key Libraries & Rationale\n\n| Library | Version | Rationale |\n|---|---|---|\n| `bertopic` | â‰¥0.16 | SOTA topic modeling: Sentence-BERT + UMAP + HDBSCAN + c-TF-IDF pipeline |\n| `umap-learn` | â‰¥0.5 | Non-linear dimensionality reduction preserving local & global topology |\n| `hdbscan` | â‰¥0.8 | Density-based clustering, no need to specify number of clusters |\n| `sentence-transformers` | â‰¥3.0 | SOTA sentence embedding models for semantic analysis |\n| `ydata-profiling` | â‰¥4.0 | Automated EDA with comprehensive HTML reports |\n| `huggingface_hub` | â‰¥0.20 | Model & dataset provenance, HF watermarking |\n\n### Relevant Whitepapers\n\n1. **BERTopic: Neural Topic Modeling with a Class-based TF-IDF** (2022). *arXiv:2203.05794*. https://arxiv.org/abs/2203.05794\n2. **Large-Scale Multidimensional Knowledge Profiling** (2026). *arXiv:2601.15170*. https://arxiv.org/abs/2601.15170\n3. **UMAP: Uniform Manifold Approximation and Projection** (2018). *arXiv:1802.03426*. https://arxiv.org/abs/1802.03426\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "#@title 01. EXECUTE: INSTALL_CORE_SYSTEMS_v7 { display-mode: 'form' }\nimport os\nimport sys\nfrom datetime import datetime\nimport time\nfrom IPython.display import display, HTML\n\n# â”€â”€â”€ ARTIFEX v7.0 BRUTALIST CSS INJECTION â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\ndef inject_artifex_style():\n    style = \"\"\"\n    <style>\n    @import url('https://fonts.googleapis.com/css2?family=Syne+Mono&family=Epilogue:wght@300;400;700&display=swap');\n    body { font-family: 'Epilogue', sans-serif; }\n    .artifex-header {\n        font-family: 'Syne Mono', monospace;\n        color: #FFFFFF;\n        background: #000000;\n        padding: 24px;\n        border: 5px solid #FF3E00;\n        text-align: center;\n        font-size: 2.5em;\n        letter-spacing: 4px;\n        margin-bottom: 20px;\n    }\n    .artifex-subheader {\n        font-family: 'Syne Mono', monospace;\n        color: #FF3E00;\n        font-size: 0.8em;\n        letter-spacing: 2px;\n    }\n    .brutalist-explainer {\n        font-family: 'Epilogue', sans-serif;\n        background: #FFFFFF;\n        color: #000000;\n        border: 4px solid #000000;\n        padding: 15px;\n        margin: 10px 0;\n        box-shadow: 10px 10px 0px #FF3E00;\n    }\n    .brutalist-table {\n        width: 100%;\n        border-collapse: collapse;\n        font-family: 'Epilogue', sans-serif;\n    }\n    .brutalist-table th {\n        background: #000000;\n        color: #FFFFFF;\n        padding: 10px;\n        border: 2px solid #000000;\n    }\n    .brutalist-table td {\n        padding: 10px;\n        border: 2px solid #000000;\n    }\n    .status-safe { color: #006600; font-weight: bold; }\n    .status-unsafe { color: #CC0000; font-weight: bold; }\n    .status-human { color: #FF8C00; font-weight: bold; }\n    </style>\n    \"\"\"\n    display(HTML(style))\n\ninject_artifex_style()\n\n# â”€â”€â”€ ARTIFEX HEADER â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nheader_html = f\"\"\"\n<div class='artifex-header'>\n    A R T I F E X &nbsp; v 7 . 0\n    <br>\n    <span class='artifex-subheader'>\n        COMPOSITIONAL SAFETY ROUTING // ENTROPY ENFORCED // 2026 SOTA\n    </span>\n    <br>\n    <span style='font-family: Epilogue; font-size: 0.25em; color: #888;'>\n        {datetime.now().strftime('%Y-%m-%d %H:%M:%S UTC')}\n    </span>\n</div>\n\"\"\"\ndisplay(HTML(header_html))\n\n# â”€â”€â”€ SOTA DEPENDENCY INSTALLATION (2026 STACK) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nprint(f\"[{datetime.now().strftime('%H:%M:%S')}] ğŸš€ Installing ARTIFEX v7.0 SOTA dependency stack...\")\n\npackages = [\n    \"bertopic>=0.16\",\n    \"hdbscan\",\n    \"umap-learn\",\n    \"sentence-transformers>=3.0\",\n    \"ydata-profiling>=4.0\",\n    \"pandas\",\n    \"pandera\",\n    \"loguru\",\n    \"tqdm\",\n    \"emoji\",\n    \"plotly\",\n    \"scikit-learn\",\n    \"huggingface_hub>=0.20\",\n    \"watermark\",\n    \"scipy\",\n    \"numpy\"\n]\n\n# Install quietly to avoid verbose output\nfor pkg in packages:\n    os.system(f\"pip install -q '{pkg}'\")\n\nimport emoji as emoji_lib\nprint(emoji_lib.emojize(f\":check_mark_button: [{datetime.now().strftime('%H:%M:%S')}] All v7.0 dependencies installed successfully.\"))\n\n# â”€â”€â”€ GLOBAL IMPORTS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nimport pandas as pd\nimport numpy as np\nfrom tqdm.notebook import tqdm\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom IPython.display import display, HTML\nimport emoji\n\ndef artifex_explainer(title, content):\n    \"\"\"Renders a Brutalist-styled HTML explainer block.\"\"\"\n    html = f\"\"\"<div class='brutalist-explainer'>\n        <h2 style='color:#FF3E00; font-family: Syne Mono, monospace;'>{title}</h2>\n        <div style='font-family: Epilogue, sans-serif;'>{content}</div>\n    </div>\"\"\"\n    display(HTML(html))\n\nprint(emoji.emojize(f\":check_mark_button: [{datetime.now().strftime('%H:%M:%S')}] ARTIFEX v7.0 System Online. Global imports complete.\"))\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# ğŸ“‚ INGESTION_STRATEGY: DATA_HANDOFF_v7\n\nThis cell manages the critical first step of data ingestion. Three distinct, user-selectable methods are provided:\n\n1. **Colab Secrets**: For securely accessing API keys or file paths stored in the Colab environment.\n2. **Mount Google Drive**: For users who store their datasets in Google Drive.\n3. **File Upload Widget**: A straightforward option for direct file uploads from the local machine.\n\nIf no file is provided, the notebook generates a **synthetic dataset** containing examples of both positive feedback and compositional harm scenarios (e.g., culturally sensitive content combinations), ensuring all ARTIFEX v7.0 features can be demonstrated out-of-the-box.\n\n### Data Schema\n\n| Column | Type | Description |\n|---|---|---|\n| `timestamp` | `datetime` | When the feedback was submitted |\n| `user_id` | `string` | Anonymized user identifier |\n| `feedback_text` | `string` | The raw feedback text (may include image descriptions) |\n| `rating` | `int` | User satisfaction rating (1=Very Negative, 5=Very Positive) |\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "#@title 02. EXECUTE: DATA_INGESTION_WORKFLOW\n#@param [\"Colab Secrets\", \"Mount Google Drive\", \"File Upload Widget\"]\nINJECTION_METHOD = \"File Upload Widget\"  #@param\n\nimport pandas as pd\nimport io\nfrom datetime import datetime\n\ntry:\n    from google.colab import files, drive\n    IN_COLAB = True\nexcept ImportError:\n    IN_COLAB = False\n    print(\"[INFO] Not running in Colab. Using synthetic data.\")\n\nprint(emoji.emojize(f\":inbox_tray: [{datetime.now().strftime('%H:%M:%S')}] Initializing data ingestion via [{INJECTION_METHOD}]...\"))\n\ndf = None\n\ntry:\n    if IN_COLAB:\n        if INJECTION_METHOD == \"Mount Google Drive\":\n            drive.mount(\"/content/drive\")\n            file_path = \"/content/drive/MyDrive/feedback_data.csv\"  # â† UPDATE THIS PATH\n            df = pd.read_csv(file_path)\n            print(emoji.emojize(f\":check_mark_button: Loaded from Google Drive.\"))\n\n        elif INJECTION_METHOD == \"File Upload Widget\":\n            uploaded = files.upload()\n            if \"feedback_data.csv\" in uploaded:\n                df = pd.read_csv(io.BytesIO(uploaded[\"feedback_data.csv\"]))\n                print(emoji.emojize(f\":check_mark_button: Loaded via file upload.\"))\n            else:\n                print(emoji.emojize(f\":warning: No `feedback_data.csv` found. Generating synthetic data.\"))\n\n        elif INJECTION_METHOD == \"Colab Secrets\":\n            from google.colab import userdata\n            # Example: load API key\n            # OPENAI_API_KEY = userdata.get(\"OPENAI_API_KEY\")\n            print(emoji.emojize(f\":key: Colab Secrets loaded. Add your API key retrieval logic here.\"))\n\nexcept Exception as e:\n    print(emoji.emojize(f\":cross_mark: Error: {e}. Falling back to synthetic data.\"))\n\n# â”€â”€â”€ SYNTHETIC DATA FALLBACK â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nif df is None:\n    print(emoji.emojize(f\":robot: [{datetime.now().strftime('%H:%M:%S')}] Generating ARTIFEX v7.0 synthetic dataset...\"))\n    data = {\n        \"timestamp\": pd.to_datetime([\n            \"2026-01-15\", \"2026-01-16\", \"2026-01-17\", \"2026-01-18\", \"2026-01-19\",\n            \"2026-01-20\", \"2026-01-21\", \"2026-01-22\", \"2026-01-23\", \"2026-01-24\",\n            \"2026-01-25\", \"2026-01-26\"\n        ]),\n        \"user_id\": [f\"user_{i:03}\" for i in range(12)],\n        \"feedback_text\": [\n            \"The model responses were biased against certain minority groups.\",\n            \"Excellent speed and very helpful for coding tasks.\",\n            \"The image of a cow is fine, but the text talks about a beef recipe. This is offensive in my culture.\",\n            \"Very responsive, but hallucinated facts about the 2024 election.\",\n            \"I love my new dog, he is a great pet and lives inside with my family in Malaysia!\",\n            \"Fast and efficient for text summarization tasks.\",\n            \"The AI is promoting violence by showing a weapon and saying final solution.\",\n            \"The UI is clean and the AI is fast and accurate.\",\n            \"This is a picture of a temple, but the text is making fun of the religion.\",\n            \"The tone of the AI was condescending and unhelpful.\",\n            \"Great model, very accurate and helpful for research.\",\n            \"The AI showed biased results when I asked about different cultures.\",\n        ],\n        \"rating\": [1, 5, 1, 2, 2, 5, 1, 5, 1, 2, 5, 1]\n    }\n    df = pd.DataFrame(data)\n    print(emoji.emojize(f\":check_mark_button: Synthetic dataset created with {len(df)} samples.\"))\n\n# â”€â”€â”€ DATA VALIDATION â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nrequired_cols = [\"timestamp\", \"user_id\", \"feedback_text\", \"rating\"]\nmissing = [c for c in required_cols if c not in df.columns]\nif missing:\n    print(emoji.emojize(f\":cross_mark: Missing required columns: {missing}\"))\nelse:\n    print(emoji.emojize(f\":check_mark_button: Schema validated. All required columns present.\"))\n\ndisplay(df.head())\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# ğŸ“Š AUTOMATED_EDA: PROFILING_ANALYSIS_v7\n\nBefore diving into complex modeling, a thorough Exploratory Data Analysis (EDA) is essential. This cell uses `ydata-profiling` to generate a comprehensive, interactive HTML report of the dataset, providing immediate insights into:\n\n- **Variable Types**: Automatically detects numerical, categorical, and text features.\n- **Distributions**: Visualizes the distribution of ratings and other numerical data.\n- **Missing Values**: Identifies any gaps in the data.\n- **Correlations**: Highlights relationships between variables.\n- **Text Statistics**: Average length, character distribution, and word frequency.\n\nThis step is critical for identifying class imbalances or text characteristics that might influence downstream embedding and clustering models.\n\n### Relevant Whitepapers\n\n1. **ydata-profiling: Exploratory Data Analysis for ML** (2024). https://github.com/ydataai/ydata-profiling\n2. **A Statistical Framework for Alignment with Biased AI Feedback** (2026). *arXiv:2602.08259*. https://arxiv.org/abs/2602.08259\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "#@title 03. EXECUTE: YDATA_PROFILING\nfrom ydata_profiling import ProfileReport\nfrom IPython.display import IFrame\n\nprint(emoji.emojize(f\":bar_chart: [{datetime.now().strftime('%H:%M:%S')}] Generating comprehensive EDA report...\"))\n\ntry:\n    profile = ProfileReport(df, title=\"ARTIFEX v7.0 Feedback Profiling\", minimal=True)\n    profile.to_file(\"artifex_v7_eda_report.html\")\n    print(emoji.emojize(f\":check_mark_button: EDA report saved to `artifex_v7_eda_report.html`.\"))\n    display(IFrame(\"artifex_v7_eda_report.html\", width=\"100%\", height=\"500\"))\nexcept Exception as e:\n    print(emoji.emojize(f\":warning: ydata-profiling error: {e}. Displaying basic stats instead.\"))\n    display(df.describe())\n    display(df.dtypes)\n\nartifex_explainer(\n    \"EDA_COMPLETE\",\n    \"Dataset profiling finished. The interactive report provides a deep dive into data quality, distributions, and correlations. Download <code>artifex_v7_eda_report.html</code> from the file panel for full inspection.\"\n)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# ğŸ§¬ VECTORIZATION: SOTA_NEURAL_EMBEDDING\n\nThis cell transforms raw `feedback_text` into rich, high-dimensional numerical representations (embeddings). We utilize `all-MiniLM-L6-v2` from the `sentence-transformers` library â€” a highly efficient model that maps each feedback entry into a **384-dimensional vector space** where semantically similar feedback points cluster together.\n\nThis is far superior to TF-IDF because it captures context, nuance, and intent rather than just keyword frequency.\n\n### Mathematical Rationale\n\nGiven a feedback text $t_i$, the encoder $f_\\theta$ produces:\n\n$$\\mathbf{e}_i = f_\\theta(t_i) \\in \\mathbb{R}^{384}$$\n\nSemantic similarity between two texts is then measured by cosine similarity:\n\n$$\\text{sim}(t_i, t_j) = \\frac{\\mathbf{e}_i \\cdot \\mathbf{e}_j}{\\|\\mathbf{e}_i\\| \\|\\mathbf{e}_j\\|}$$\n\n### Relevant Whitepapers\n\n1. **Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks** (2019). *arXiv:1908.10084*. https://arxiv.org/abs/1908.10084\n2. **Bridging the Semantic Gap for Categorical Data Clustering via LLMs** (2026). *arXiv:2601.01162*. https://arxiv.org/abs/2601.01162\n3. **SDEC: Semantic Deep Embedded Clustering** (2025). *IEEE*. https://ieeexplore.ieee.org/abstract/document/11142675/\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "#@title 04. EXECUTE: TRANSFORMER_EMBEDDING\nfrom sentence_transformers import SentenceTransformer\nimport numpy as np\n\nprint(emoji.emojize(f\":dna: [{datetime.now().strftime('%H:%M:%S')}] Loading SOTA sentence embedding model (all-MiniLM-L6-v2)...\"))\n\ntry:\n    model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n    print(emoji.emojize(f\":rocket: [{datetime.now().strftime('%H:%M:%S')}] Encoding {len(df)} feedback texts into 384-dimensional vectors...\"))\n\n    embeddings = model.encode(\n        df[\"feedback_text\"].tolist(),\n        show_progress_bar=True,\n        batch_size=32\n    )\n\n    df[\"embedding\"] = list(embeddings)\n    print(emoji.emojize(f\":check_mark_button: Vectorization complete. Shape: {embeddings.shape}\"))\n\n    artifex_explainer(\n        \"EMBEDDING_COMPLETE\",\n        f\"Successfully vectorized <strong>{len(df)}</strong> text samples into a <strong>{embeddings.shape[1]}-dimensional</strong> latent space. \"\n        f\"These embeddings represent the semantic DNA of the feedback, ready for BERTopic clustering and UMAP projection.\"\n    )\n\nexcept Exception as e:\n    print(emoji.emojize(f\":cross_mark: Embedding error: {e}\"))\n    # Fallback: use TF-IDF embeddings\n    from sklearn.feature_extraction.text import TfidfVectorizer\n    print(emoji.emojize(f\":warning: Falling back to TF-IDF embeddings...\"))\n    tfidf = TfidfVectorizer(max_features=100)\n    embeddings = tfidf.fit_transform(df[\"feedback_text\"]).toarray()\n    df[\"embedding\"] = list(embeddings)\n    print(emoji.emojize(f\":check_mark_button: TF-IDF fallback complete. Shape: {embeddings.shape}\"))\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# â¬¢ UNSUPERVISED_LEARNING: BERTopic_CLUSTERING\n\nThis cell represents the **core upgrade from v6.1**, replacing traditional K-Means with **BERTopic** â€” a state-of-the-art topic modeling technique. BERTopic's pipeline:\n\n1. **Embedding**: Uses the high-quality sentence embeddings from Cell 04.\n2. **Dimensionality Reduction**: Applies **UMAP** to reduce to a lower-dimensional space, combating the \"curse of dimensionality.\"\n3. **Clustering**: Applies **HDBSCAN** â€” a density-based algorithm that finds clusters of varying shapes without requiring a pre-specified number of clusters.\n4. **Topic Representation**: Uses **c-TF-IDF** to extract the most representative keywords for each cluster.\n\n### Why BERTopic > K-Means\n\n| Feature | K-Means (v6.1) | BERTopic (v7.0) |\n|---|---|---|\n| Number of clusters | Must be pre-specified | Automatically determined |\n| Cluster shape | Spherical only | Any shape (density-based) |\n| Outlier handling | None | Explicit outlier class (-1) |\n| Topic labels | None | Human-readable keyword labels |\n| SOTA status | Classical (1967) | State-of-the-art (2022-2026) |\n\n### Relevant Whitepapers\n\n1. **BERTopic: Neural Topic Modeling with a Class-based TF-IDF** (2022). *arXiv:2203.05794*. https://arxiv.org/abs/2203.05794\n2. **Transformer Semantic Topic Modeling** (2026). *Emergent Mind*. https://www.emergentmind.com/topics/transformer-based-semantic-topic-modeling\n3. **Large-Scale Multidimensional Knowledge Profiling** (2026). *arXiv:2601.15170*. https://arxiv.org/abs/2601.15170\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "#@title 05. EXECUTE: BERTopic_SEMANTIC_CLUSTERING\nfrom bertopic import BERTopic\nfrom sklearn.metrics import silhouette_score\nimport numpy as np\n\nprint(emoji.emojize(f\":brain: [{datetime.now().strftime('%H:%M:%S')}] Initializing BERTopic model for SOTA semantic clustering...\"))\n\ntry:\n    # Configure BERTopic with explicit UMAP and HDBSCAN parameters\n    from umap import UMAP\n    from hdbscan import HDBSCAN\n\n    umap_model = UMAP(n_neighbors=5, n_components=5, min_dist=0.0, metric='cosine', random_state=42)\n    hdbscan_model = HDBSCAN(min_cluster_size=2, metric='euclidean', cluster_selection_method='eom', prediction_data=True)\n\n    topic_model = BERTopic(\n        umap_model=umap_model,\n        hdbscan_model=hdbscan_model,\n        min_topic_size=2,\n        verbose=False\n    )\n\n    # Fit the model using pre-computed embeddings for efficiency\n    topics, probs = topic_model.fit_transform(df[\"feedback_text\"], embeddings)\n    df[\"cluster\"] = topics\n\n    n_topics = len(topic_model.get_topic_info()) - 1  # Exclude outlier topic (-1)\n    n_outliers = len(df[df[\"cluster\"] == -1])\n\n    print(emoji.emojize(f\":chart_increasing: Identified {n_topics} distinct topics. {n_outliers} outliers detected.\"))\n\n    # Silhouette Score for non-outlier points\n    valid_mask = df[\"cluster\"] != -1\n    if valid_mask.sum() > 1 and len(df[valid_mask][\"cluster\"].unique()) > 1:\n        score = silhouette_score(\n            np.array(df[valid_mask][\"embedding\"].tolist()),\n            df[valid_mask][\"cluster\"]\n        )\n    else:\n        score = 0.0\n\n    table_html = f\"\"\"\n    <table class='brutalist-table'>\n        <tr><th>Metric</th><th>Value</th><th>Interpretation</th></tr>\n        <tr><td>Identified Topics</td><td><strong>{n_topics}</strong></td><td>Distinct semantic groups (auto-detected)</td></tr>\n        <tr><td>Outliers</td><td><strong>{n_outliers}</strong></td><td>Feedback not fitting any topic</td></tr>\n        <tr><td>Silhouette Score</td><td><strong>{score:.4f}</strong></td><td>Cluster quality: higher is better (range -1 to 1)</td></tr>\n    </table>\n    \"\"\"\n    artifex_explainer(\"BERTopic CLUSTERING COMPLETE\", table_html)\n\n    print(\"\\n--- Topic Keywords (Top 5 per topic) ---\")\n    display(topic_model.get_topic_info().head(10))\n\nexcept Exception as e:\n    print(emoji.emojize(f\":warning: BERTopic error: {e}. Falling back to K-Means...\"))\n    from sklearn.cluster import KMeans\n    N_CLUSTERS = 3\n    kmeans = KMeans(n_clusters=N_CLUSTERS, random_state=42, n_init='auto')\n    df[\"cluster\"] = kmeans.fit_predict(np.array(df[\"embedding\"].tolist()))\n    print(emoji.emojize(f\":check_mark_button: K-Means fallback complete with {N_CLUSTERS} clusters.\"))\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# ğŸŒŒ VISUALIZATION: UMAP_LATENT_SPACE_MAPPING\n\nTo visually inspect the quality of our semantic clustering, we project the high-dimensional embeddings into a human-perceivable 3D space using **UMAP (Uniform Manifold Approximation and Projection)** â€” a significant upgrade from the PCA method used in v6.1.\n\n### UMAP vs PCA\n\n| Property | PCA (v6.1) | UMAP (v7.0) |\n|---|---|---|\n| Type | Linear | Non-linear (manifold learning) |\n| Preserves | Global variance | Local AND global topology |\n| Computational cost | Low | Moderate |\n| Cluster separation | Often poor | Excellent |\n| SOTA status | Classical (1901) | State-of-the-art (2018-2026) |\n\nThe interactive 3D scatter plot allows you to rotate and explore the semantic landscape of the feedback. Points that are close together share similar semantic meaning.\n\n### Relevant Whitepapers\n\n1. **UMAP: Uniform Manifold Approximation and Projection** (2018). *arXiv:1802.03426*. https://arxiv.org/abs/1802.03426\n2. **An empirical evaluation of dimensionality reduction** (2025). *Scientific Reports*. https://www.nature.com/articles/s41598-025-30537-w\n3. **Comprehensive review of dimensionality reduction algorithms** (2025). *PeerJ Computer Science*. https://peerj.com/articles/cs-3025/\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "#@title 05.1 EXECUTE: 3D_UMAP_LATENT_PROJECTION\nfrom umap import UMAP\nimport plotly.express as px\nimport numpy as np\n\nprint(emoji.emojize(f\":milky_way: [{datetime.now().strftime('%H:%M:%S')}] Performing UMAP 3D dimensionality reduction...\"))\n\ntry:\n    umap_3d = UMAP(n_neighbors=5, min_dist=0.3, n_components=3, random_state=42)\n    components = umap_3d.fit_transform(np.array(df[\"embedding\"].tolist()))\n\n    df[\"umap_x\"] = components[:, 0]\n    df[\"umap_y\"] = components[:, 1]\n    df[\"umap_z\"] = components[:, 2]\n\n    print(emoji.emojize(f\":sparkles: Generating interactive 3D UMAP projection...\"))\n\n    fig = px.scatter_3d(\n        df,\n        x=\"umap_x\", y=\"umap_y\", z=\"umap_z\",\n        color=\"cluster\",\n        hover_data=[\"feedback_text\", \"rating\"],\n        title=\"ARTIFEX v7.0: UMAP Latent Space Projection\",\n        template=\"plotly_dark\",\n        color_continuous_scale=\"Portland\"\n    )\n\n    fig.update_layout(\n        font_family=\"Syne Mono\",\n        scene=dict(\n            xaxis=dict(backgroundcolor=\"black\", gridcolor=\"white\", title=\"UMAP_1\"),\n            yaxis=dict(backgroundcolor=\"black\", gridcolor=\"white\", title=\"UMAP_2\"),\n            zaxis=dict(backgroundcolor=\"black\", gridcolor=\"white\", title=\"UMAP_3\")\n        ),\n        margin=dict(l=0, r=0, b=0, t=40)\n    )\n\n    fig.show()\n\n    artifex_explainer(\n        \"UMAP PROJECTION COMPLETE\",\n        \"The 3D scatter plot above represents the semantic DNA of the feedback, projected by UMAP. \"\n        \"Proximate points share contextual meaning. Use your mouse to rotate and explore the clusters. \"\n        \"This non-linear projection reveals the true topological structure of the feedback far more accurately than PCA.\"\n    )\n\nexcept Exception as e:\n    print(emoji.emojize(f\":warning: UMAP error: {e}. Falling back to PCA visualization...\"))\n    from sklearn.decomposition import PCA\n    pca = PCA(n_components=3)\n    components = pca.fit_transform(np.array(df[\"embedding\"].tolist()))\n    df[\"umap_x\"] = components[:, 0]\n    df[\"umap_y\"] = components[:, 1]\n    df[\"umap_z\"] = components[:, 2]\n    fig = px.scatter_3d(df, x=\"umap_x\", y=\"umap_y\", z=\"umap_z\", color=\"cluster\",\n                        hover_data=[\"feedback_text\"], title=\"PCA Fallback Projection\",\n                        template=\"plotly_dark\")\n    fig.show()\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# ğŸ›¡ï¸ COMPOSITIONAL_SAFETY: MULTI_AGENT_SWARM_v7\n\nThis cell contains the **core innovation of ARTIFEX v7.0**: a multi-agent swarm for **Compositional Safety Analysis**. Traditional moderation systems fail by evaluating modalities in isolation. ARTIFEX detects *emergent harm* â€” unsafe meaning arising from the combination of individually safe components.\n\n### ARTIFEX v7 Swarm Architecture (2026 SOTA)\n\n| Agent ID | Role | SOTA Influence |\n| :--- | :--- | :--- |\n| **A-0.5** | `LOCALE_SENSOR` | Informed by **Multi3Hate** (NAACL 2025): cultural background significantly affects harm perception |\n| **A-01** | `TEXT_AUDITOR` | Standard keyword-based explicit harm detection |\n| **A-02** | `VISION_AUDITOR` | Simulated; in production uses **OmniSteer** (arXiv:2602.10161) |\n| **A-03** | **`COMPOSITIONAL_CORE`** | Inspired by **Omni-Safety** modality-semantics decoupling principle |\n| **A-04** | `ENTROPY_CALCULATOR` | Based on **LLM Performance Predictors** (AAMAS 2026, arXiv:2601.07006) |\n| **A-10** | `GOVERNANCE_HEAD` | Inspired by **Aetheria** interpretable audit trail generation (arXiv:2512.02530) |\n\n### The Entropy-Enforced Routing Logic\n\nThe key innovation is using **Shannon entropy** $H$ to quantify agent disagreement:\n\n$$H(V) = -\\sum_{v \\in V} p(v) \\log_2 p(v)$$\n\nWhere $V$ is the set of agent verdicts. High entropy (disagreement) triggers human escalation.\n\n### Relevant Whitepapers\n\n1. **Multi3Hate: Multimodal, Multilingual, and Multicultural Hate Speech Detection** (NAACL 2025). *arXiv:2411.03888*. https://arxiv.org/abs/2411.03888\n2. **Omni-Safety under Cross-Modality Conflict** (Feb 2026). *arXiv:2602.10161*. https://arxiv.org/abs/2602.10161\n3. **LLM Performance Predictors: Learning When to Escalate** (AAMAS 2026). *arXiv:2601.07006*. https://arxiv.org/abs/2601.07006\n4. **Aetheria: A multimodal interpretable content safety framework** (Dec 2025). *arXiv:2512.02530*. https://arxiv.org/abs/2512.02530\n5. **Socio-Culturally Aware Evaluation Framework for LLM Content Moderation** (2024). *arXiv:2412.13578*. https://arxiv.org/abs/2412.13578\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "#@title 06. EXECUTE: ARTIFEX_SWARM_INFERENCE\nimport numpy as np\nfrom scipy.stats import entropy as scipy_entropy\nfrom datetime import datetime\n\nprint(emoji.emojize(f\":shield: [{datetime.now().strftime('%H:%M:%S')}] Initializing ARTIFEX v7.0 Multi-Agent Swarm...\"))\n\n# â”€â”€â”€ AGENT SWARM DEFINITION â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nclass ArtifexSwarmV7:\n    \"\"\"\n    ARTIFEX v7.0 Multi-Agent Compositional Safety Swarm.\n    Implements entropy-based routing inspired by LLM Performance Predictors (AAMAS 2026).\n    Cultural context database informed by Multi3Hate (NAACL 2025).\n    \"\"\"\n\n    def __init__(self):\n        # Cultural context database â€” expanded based on Multi3Hate findings\n        # (Bui et al., 2025): USA-India pairwise agreement only 67%\n        self.cultural_db = {\n            \"India\": {\n                \"taboos\": [\"beef recipe\", \"cow slaughter\", \"disrespecting elders\"],\n                \"sensitivities\": [\"religious imagery\", \"caste references\"]\n            },\n            \"Malaysia\": {\n                \"taboos\": [\"dog as indoor pet\", \"pork/alcohol\", \"left hand\"],\n                \"sensitivities\": [\"halal violations\", \"religious mixing\"]\n            },\n            \"USA\": {\n                \"sensitivities\": [\"gun violence\", \"political polarization\", \"racial slurs\"]\n            },\n            \"Brazil\": {\n                \"taboos\": [\"OK hand sign (offensive gesture)\"],\n                \"sensitivities\": [\"racial references\"]\n            },\n            \"Global\": {\"taboos\": [], \"sensitivities\": []}\n        }\n\n    # â”€â”€ AGENT 0.5: LOCALE_SENSOR â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n    def classify_locale(self, text):\n        \"\"\"Infers cultural locale from text cues. Based on Multi3Hate findings.\"\"\"\n        text_lower = text.lower()\n        locale_keywords = {\n            \"India\": [\"delhi\", \"rupee\", \"hindi\", \"cow\", \"temple\", \"india\", \"south asian\"],\n            \"Malaysia\": [\"kl\", \"ringgit\", \"malay\", \"halal\", \"malaysia\", \"kuala lumpur\"],\n            \"Brazil\": [\"rio\", \"real\", \"carnival\", \"brazil\", \"brasil\"],\n            \"USA\": [\"election\", \"texas\", \"california\", \"dollar\", \"usa\", \"america\"]\n        }\n        for locale, keywords in locale_keywords.items():\n            if any(kw in text_lower for kw in keywords):\n                return locale\n        return \"Global\"\n\n    # â”€â”€ AGENT 01: TEXT_AUDITOR â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n    def analyze_text(self, text):\n        \"\"\"Scans for explicit keyword-based violations.\"\"\"\n        explicit_triggers = [\"kill\", \"hate\", \"die\", \"murder\", \"attack\", \"violence\",\n                             \"final solution\", \"genocide\", \"slur\"]\n        if any(t in text.lower() for t in explicit_triggers):\n            return {\"label\": \"UNSAFE\", \"confidence\": 0.95, \"reason\": \"Explicit Violence/Hate Speech\"}\n        return {\"label\": \"SAFE\", \"confidence\": 0.90, \"reason\": \"No explicit violation\"}\n\n    # â”€â”€ AGENT 02: VISION_AUDITOR (Simulated) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n    def analyze_image(self, text):\n        \"\"\"\n        Simulates visual harm detection.\n        In production: uses OmniSteer (arXiv:2602.10161) for cross-modal safety.\n        \"\"\"\n        text_lower = text.lower()\n        if \"image of a cow\" in text_lower or \"picture of a cow\" in text_lower:\n            return {\"label\": \"SAFE\", \"confidence\": 0.85, \"reason\": \"Image depicts a cow (neutral object)\"}\n        if \"picture of a temple\" in text_lower or \"image of a temple\" in text_lower:\n            return {\"label\": \"SAFE\", \"confidence\": 0.85, \"reason\": \"Image depicts a temple (neutral object)\"}\n        if \"showing a weapon\" in text_lower or \"image of a weapon\" in text_lower:\n            return {\"label\": \"UNSAFE\", \"confidence\": 0.95, \"reason\": \"Image depicts a weapon\"}\n        return {\"label\": \"SAFE\", \"confidence\": 0.80, \"reason\": \"No visual violations detected (simulated)\"}\n\n    # â”€â”€ AGENT 03: COMPOSITIONAL_CORE â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n    def analyze_composition(self, text, locale, text_verdict, img_verdict):\n        \"\"\"\n        The Liaison Agent. Detects emergent cross-modal harm.\n        Inspired by Omni-Safety modality-semantics decoupling (arXiv:2602.10161).\n        \"\"\"\n        text_lower = text.lower()\n\n        # Rule 1: India + Cow + Food/Recipe = Compositional Harm (Beef taboo)\n        if locale == \"India\" and \"cow\" in text_lower and (\"recipe\" in text_lower or \"food\" in text_lower):\n            return {\"label\": \"UNSAFE\", \"confidence\": 0.92,\n                    \"mechanism\": \"Compositional Harm: Beef consumption taboo in India (A-0.5 + A-02 + A-03 trigger)\"}\n\n        # Rule 2: Malaysia + Dog + Indoor Pet = Compositional Harm (Cultural sensitivity)\n        if locale == \"Malaysia\" and \"dog\" in text_lower and (\"pet\" in text_lower or \"inside\" in text_lower):\n            return {\"label\": \"UNSAFE\", \"confidence\": 0.88,\n                    \"mechanism\": \"Compositional Harm: Cultural sensitivity re: dogs as indoor pets in Malaysia\"}\n\n        # Rule 3: Religious imagery + Disrespectful text = Compositional Harm\n        if (\"temple\" in text_lower or \"mosque\" in text_lower or \"church\" in text_lower) and            (\"making fun\" in text_lower or \"mocking\" in text_lower or \"offensive\" in text_lower):\n            return {\"label\": \"UNSAFE\", \"confidence\": 0.90,\n                    \"mechanism\": \"Compositional Harm: Disrespectful text combined with religious imagery\"}\n\n        # Fallback: Inherit unsafety from unimodal agents\n        if text_verdict == \"UNSAFE\" or img_verdict == \"UNSAFE\":\n            return {\"label\": \"UNSAFE\", \"confidence\": 0.95,\n                    \"mechanism\": \"Inherited unimodal violation (A-01 or A-02)\"}\n\n        return {\"label\": \"SAFE\", \"confidence\": 0.85, \"mechanism\": \"No compositional harm detected\"}\n\n    # â”€â”€ AGENT 04: ENTROPY_CALCULATOR â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n    def calculate_entropy(self, verdicts):\n        \"\"\"\n        Calculates Shannon entropy of agent verdicts.\n        Based on LLM Performance Predictors framework (AAMAS 2026, arXiv:2601.07006).\n        High entropy = high disagreement = route to human.\n        \"\"\"\n        numerical = [1 if v == \"UNSAFE\" else 0 for v in verdicts]\n        _, counts = np.unique(numerical, return_counts=True)\n        probs = counts / len(numerical)\n        return float(scipy_entropy(probs, base=2))\n\n    # â”€â”€ AGENT 10: GOVERNANCE_HEAD â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n    def generate_rubric(self, text, mechanism):\n        \"\"\"\n        Generates adaptive boolean rubrics for human reviewers.\n        Inspired by Aetheria interpretable audit trail (arXiv:2512.02530).\n        \"\"\"\n        text_lower = text.lower()\n        if \"cow\" in text_lower and \"recipe\" in text_lower:\n            return [\n                \"Does the image depict cattle/a cow?\",\n                \"Does the text imply consumption or preparation of beef?\",\n                \"Is the cultural context specifically South Asian/Indian?\"\n            ]\n        if \"dog\" in text_lower and \"pet\" in text_lower:\n            return [\n                \"Is the context a Muslim-majority region?\",\n                \"Does the text imply the dog is kept inside the home?\",\n                \"Is there any religious framing in the content?\"\n            ]\n        if \"temple\" in text_lower or \"religion\" in text_lower:\n            return [\n                \"Does the image depict a religious site or symbol?\",\n                \"Is the text disrespectful or mocking toward the religion?\",\n                \"Could this content incite religious offense?\"\n            ]\n        return [\n            \"Is there explicit violence or hate speech in the text?\",\n            \"Are hate symbols or weapons visible in the image?\",\n            \"Does the combination of text and image create harmful meaning?\"\n        ]\n\n    # â”€â”€ MAIN INFERENCE LOOP â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n    def run_inference(self, df):\n        print(emoji.emojize(f\"\\n:robot: [{datetime.now().strftime('%H:%M:%S')}] Running ARTIFEX Swarm Inference on {len(df)} samples...\"))\n        results = []\n\n        for _, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Swarm Analysis\", ncols=100):\n            text = row[\"feedback_text\"]\n\n            # Agent chain execution\n            locale = self.classify_locale(text)\n            v1 = self.analyze_text(text)\n            v2 = self.analyze_image(text)\n            v3 = self.analyze_composition(text, locale, v1[\"label\"], v2[\"label\"])\n\n            # Entropy calculation (Agent 04)\n            verdicts = [v1[\"label\"], v2[\"label\"], v3[\"label\"]]\n            entropy_score = self.calculate_entropy(verdicts)\n\n            # Routing logic: entropy-enforced escalation\n            # Threshold of 0.9 bits based on LPP framework (arXiv:2601.07006)\n            if entropy_score > 0.9:\n                status = \"ROUTED_TO_HUMAN\"\n                routing_reason = f\"High Entropy ({entropy_score:.2f} bits): Compositional risk detected â€” agents disagree.\"\n            elif \"UNSAFE\" in verdicts:\n                status = \"AUTO_BLOCKED\"\n                routing_reason = f\"Low Entropy ({entropy_score:.2f} bits): Explicit violation â€” unanimous agent agreement.\"\n            else:\n                status = \"AUTO_APPROVED\"\n                routing_reason = f\"Low Entropy ({entropy_score:.2f} bits): No violations â€” unanimous agent agreement.\"\n\n            # Governance rubric (Agent 10)\n            rubric = self.generate_rubric(text, v3[\"mechanism\"])\n\n            results.append({\n                \"text\": text[:80] + \"...\" if len(text) > 80 else text,\n                \"locale\": locale,\n                \"text_verdict\": v1[\"label\"],\n                \"image_verdict\": v2[\"label\"],\n                \"compositional_verdict\": v3[\"label\"],\n                \"compositional_mechanism\": v3[\"mechanism\"],\n                \"entropy_bits\": round(entropy_score, 4),\n                \"final_status\": status,\n                \"routing_reason\": routing_reason,\n                \"governance_rubric\": \" | \".join(rubric)\n            })\n\n        return pd.DataFrame(results)\n\n# â”€â”€â”€ EXECUTE THE SWARM â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nswarm = ArtifexSwarmV7()\nresults_df = swarm.run_inference(df)\nresults_df[\"rating\"] = df[\"rating\"].values\nresults_df[\"cluster\"] = df[\"cluster\"].values\n\nprint(emoji.emojize(f\"\\n:check_mark_button: [{datetime.now().strftime('%H:%M:%S')}] Swarm inference complete.\"))\n\n# â”€â”€â”€ DISPLAY RESULTS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nstatus_counts = results_df[\"final_status\"].value_counts()\n\nsummary_rows = \"\".join([\n    f\"<tr><td><span class='status-{s.lower().replace('_', '-').replace('auto-blocked', 'unsafe').replace('auto-approved', 'safe').replace('routed-to-human', 'human')}'>{s}</span></td><td>{c}</td><td>{c/len(results_df)*100:.1f}%</td></tr>\"\n    for s, c in status_counts.items()\n])\n\nartifex_explainer(\n    \"SWARM_ANALYSIS_COMPLETE\",\n    f\"\"\"<table class='brutalist-table'>\n        <tr><th>Routing Decision</th><th>Count</th><th>Percentage</th></tr>\n        {summary_rows}\n    </table>\n    <p style='margin-top:10px;'>High-entropy cases (compositional harm) are automatically escalated for human review with adaptive governance rubrics. This is the core of ARTIFEX v7.0's safety architecture.</p>\"\"\"\n)\n\ndisplay(results_df)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# ğŸ§  COGNITIVE_SYNTHESIS: LLM_CLUSTER_SUMMARIZATION\n\nAfter identifying semantic clusters with BERTopic, we use a Large Language Model to synthesize a descriptive, human-readable theme for each cluster. This transforms raw keyword lists into actionable insights.\n\n**Configuration**: This cell is designed to work with **Gemini 2.0 Flash** via the OpenAI-compatible API, or with any OpenAI-compatible endpoint. Store your API key in Colab Secrets as `OPENAI_API_KEY` or `GEMINI_API_KEY`.\n\n### Relevant Whitepapers\n\n1. **Building Intelligent User Interfaces for Human-AI Alignment** (Feb 2026). *arXiv:2602.11753*. https://arxiv.org/abs/2602.11753\n2. **A Statistical Framework for Alignment with Biased AI Feedback** (Feb 2026). *arXiv:2602.08259*. https://arxiv.org/abs/2602.08259\n3. **A framework for mitigating malicious RLHF feedback (COBRA)** (2025). *Nature Scientific Reports*. https://www.nature.com/articles/s41598-025-92889-7\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "#@title 07. EXECUTE: LLM_CLUSTER_SYNTHESIS\nfrom datetime import datetime\n\nprint(emoji.emojize(f\":speech_balloon: [{datetime.now().strftime('%H:%M:%S')}] Synthesizing cluster themes...\"))\n\n# â”€â”€â”€ OPTIONAL: LIVE LLM SYNTHESIS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n# Uncomment and configure to use a real LLM API (Gemini 2.0 Flash recommended)\n#\n# try:\n#     from google.colab import userdata\n#     import openai\n#     client = openai.OpenAI(\n#         api_key=userdata.get(\"GEMINI_API_KEY\"),\n#         base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n#     )\n#     def llm_synthesize(texts):\n#         prompt = f\"Synthesize a short theme label (5-8 words) for these feedback items:\\n- \" + \"\\n- \".join(texts[:5])\n#         response = client.chat.completions.create(\n#             model=\"gemini-2.0-flash\",\n#             messages=[{\"role\": \"user\", \"content\": prompt}]\n#         )\n#         return response.choices[0].message.content.strip()\n# except Exception as e:\n#     print(f\"LLM API not configured: {e}. Using rule-based synthesis.\")\n\n# â”€â”€â”€ RULE-BASED SYNTHESIS (FALLBACK / DEFAULT) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\ndef synthesize_cluster_themes(cluster_id, df):\n    \"\"\"Synthesizes a descriptive theme for a cluster using rule-based logic.\"\"\"\n    if cluster_id == -1:\n        return \"Outliers / Noise (No Clear Topic)\"\n\n    cluster_texts = df[df[\"cluster\"] == cluster_id][\"feedback_text\"].str.lower().tolist()\n    combined = \" \".join(cluster_texts)\n\n    # Theme detection rules\n    if any(w in combined for w in [\"biased\", \"bias\", \"ethical\", \"fairness\"]):\n        return \"Ethical Concerns: Bias & Fairness Issues\"\n    if any(w in combined for w in [\"fast\", \"speed\", \"efficient\", \"quick\", \"helpful\"]):\n        return \"Positive Feedback: Performance & Efficiency\"\n    if any(w in combined for w in [\"hallucinated\", \"hallucination\", \"incorrect\", \"wrong facts\"]):\n        return \"Safety Issue: Factual Hallucinations\"\n    if any(w in combined for w in [\"violence\", \"weapon\", \"final solution\", \"explicit\"]):\n        return \"Safety Issue: Explicit Harmful Content\"\n    if any(w in combined for w in [\"cow\", \"recipe\", \"dog\", \"pet\", \"temple\", \"religion\", \"offensive\"]):\n        return \"Safety Issue: Compositional & Cultural Harm\"\n    if any(w in combined for w in [\"condescending\", \"tone\", \"unhelpful\", \"rude\"]):\n        return \"Negative Feedback: Tone & Interaction Quality\"\n\n    return f\"General Discussion: Topic Cluster {cluster_id}\"\n\n# Get unique cluster IDs\ncluster_ids = sorted(df[\"cluster\"].unique())\nsynthesis_results = {cid: synthesize_cluster_themes(cid, df) for cid in cluster_ids}\n\n# Map themes to results dataframe\nresults_df[\"cluster_theme\"] = results_df[\"cluster\"].map(synthesis_results)\n\n# Display results\ntable_rows = \"\".join([\n    f\"<tr><td><strong>{cid}</strong></td><td>{theme}</td></tr>\"\n    for cid, theme in synthesis_results.items()\n])\n\nartifex_explainer(\n    \"LLM SYNTHESIS COMPLETE\",\n    f\"\"\"<table class='brutalist-table'>\n        <tr><th>Cluster ID</th><th>Synthesized Theme</th></tr>\n        {table_rows}\n    </table>\n    <p style='margin-top:10px;'>To use live LLM synthesis with Gemini 2.0 Flash, uncomment the API section above and add your API key to Colab Secrets.</p>\"\"\"\n)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# ğŸŒŠ DYNAMICS: SENTIMENT_FLOW_ANALYSIS\n\nA **Sankey Diagram** maps the flow between the AI-identified semantic clusters and the human-provided user ratings, revealing the **\"Ethical Delta\"** â€” the gap between what the AI detects and what users actually feel.\n\n**Key Insights to Look For**:\n- Do ethical concern clusters consistently receive low ratings (1-2)?\n- Is positive performance feedback always associated with high ratings (4-5)?\n- Are there unexpected connections that suggest misalignment between AI analysis and human sentiment?\n\nThe width of each band represents the volume of feedback flowing between a cluster and a rating level.\n\n### Relevant Whitepapers\n\n1. **Human-AI Interaction Alignment** (2025). *arXiv:2512.21551*. https://arxiv.org/abs/2512.21551\n2. **Content Moderation by LLM: From Accuracy to Legitimacy** (2024). *arXiv:2409.03219*. https://arxiv.org/abs/2409.03219\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "#@title 08. EXECUTE: SANKEY_DYNAMICS\nimport plotly.graph_objects as go\nimport pandas as pd\n\nprint(emoji.emojize(f\":ocean: [{datetime.now().strftime('%H:%M:%S')}] Generating Cluster-to-Rating Semantic Flow diagram...\"))\n\ntry:\n    flow_df = results_df.copy()\n    flow_df[\"rating_label\"] = flow_df[\"rating\"].apply(lambda x: f\"Rating: {int(x)} {'â˜…' * int(x)}\")\n\n    # Create links between cluster themes and ratings\n    links = flow_df.groupby([\"cluster_theme\", \"rating_label\"]).size().reset_index(name=\"value\")\n\n    # Build node list\n    all_nodes = list(pd.concat([links[\"cluster_theme\"], links[\"rating_label\"]]).unique())\n\n    # Color mapping for routing status\n    node_colors = []\n    for node in all_nodes:\n        if \"Positive\" in node or \"Rating: 5\" in node or \"Rating: 4\" in node:\n            node_colors.append(\"#006600\")\n        elif \"Safety\" in node or \"Rating: 1\" in node or \"Ethical\" in node:\n            node_colors.append(\"#CC0000\")\n        elif \"Rating: 3\" in node:\n            node_colors.append(\"#FF8C00\")\n        else:\n            node_colors.append(\"#FF3E00\")\n\n    link_dict = {\n        \"source\": [all_nodes.index(c) for c in links[\"cluster_theme\"]],\n        \"target\": [all_nodes.index(r) for r in links[\"rating_label\"]],\n        \"value\": links[\"value\"],\n        \"color\": \"rgba(255, 62, 0, 0.35)\"\n    }\n\n    node_dict = {\n        \"pad\": 20,\n        \"thickness\": 25,\n        \"line\": dict(color=\"black\", width=0.5),\n        \"label\": all_nodes,\n        \"color\": node_colors\n    }\n\n    fig = go.Figure(data=[go.Sankey(node=node_dict, link=link_dict)])\n\n    fig.update_layout(\n        title_text=\"ARTIFEX v7.0: Cluster-to-Rating Semantic Flow (The Ethical Delta)\",\n        font_family=\"Syne Mono\",\n        paper_bgcolor=\"white\",\n        font_size=11,\n        height=500\n    )\n\n    fig.show()\n\n    artifex_explainer(\n        \"FLOW_ANALYSIS_COMPLETE\",\n        \"The Sankey diagram illustrates the distribution of user sentiment across identified semantic themes. \"\n        \"Wide bands indicate strong correlation between a topic and a specific rating. \"\n        \"Safety issues flowing to low ratings (1-2) confirm the alignment between AI-detected harm and human dissatisfaction â€” the core validation of the ARTIFEX system.\"\n    )\n\nexcept Exception as e:\n    print(emoji.emojize(f\":warning: Sankey error: {e}\"))\n    print(\"Displaying tabular summary instead:\")\n    display(results_df.groupby([\"cluster_theme\", \"rating\"]).size().reset_index(name=\"count\"))\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# ğŸ›¡ï¸ SYSTEM_HEALTH: WATERMARK_TRACKING\n\nThis final cell performs a comprehensive system audit to ensure **scientific reproducibility**. The `%watermark` magic command generates a digital fingerprint of the execution environment, including Python version, library versions, and machine information.\n\nThis is a critical step in any serious data science workflow and a core tenet of the Artifex Labs methodology for trustworthy AI research.\n\n### Relevant Whitepapers\n\n1. **A Safety and Security Framework for Real-World Agentic Systems** (2025). *arXiv:2511.21990*. https://arxiv.org/abs/2511.21990\n2. **Governing AI Agents** (2025). *arXiv:2501.07913*. https://arxiv.org/abs/2501.07913\n3. **Agentic AI Risk-Management Standards Profile** (2026). *UC Berkeley CLTC*. https://cltc.berkeley.edu/wp-content/uploads/2026/02/Agentic-AI-Risk-Management-Standards-Profile.pdf\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "#@title 09. EXECUTE: ENVIRONMENT_AUDIT\nfrom datetime import datetime\n\nprint(emoji.emojize(f\":computer: [{datetime.now().strftime('%H:%M:%S')}] Generating system and library watermark...\"))\n\ntry:\n    %load_ext watermark\n    %watermark -v -m -p pandas,numpy,sklearn,plotly,scipy,sentence_transformers,bertopic,hdbscan,umap\nexcept Exception as e:\n    print(f\"Watermark extension error: {e}\")\n    import sys, platform\n    print(f\"Python: {sys.version}\")\n    print(f\"Platform: {platform.platform()}\")\n    try:\n        import pandas, numpy, sklearn, plotly, scipy\n        print(f\"pandas: {pandas.__version__}\")\n        print(f\"numpy: {numpy.__version__}\")\n        print(f\"scikit-learn: {sklearn.__version__}\")\n        print(f\"plotly: {plotly.__version__}\")\n        print(f\"scipy: {scipy.__version__}\")\n    except Exception as e2:\n        print(f\"Could not retrieve library versions: {e2}\")\n\nartifex_explainer(\n    \"AUDIT_COMPLETE\",\n    f\"\"\"\n    <p>ARTIFEX v7.0 notebook execution finished at <strong>{datetime.now().strftime('%Y-%m-%d %H:%M:%S UTC')}</strong>.</p>\n    <p>The system environment and library versions have been logged above to ensure reproducibility.</p>\n    <p style='margin-top:10px;'><strong>ARTIFEX v7.0 Pipeline Summary:</strong></p>\n    <table class='brutalist-table'>\n        <tr><th>Stage</th><th>Method</th><th>SOTA Reference</th></tr>\n        <tr><td>Embedding</td><td>all-MiniLM-L6-v2 (384-dim)</td><td>Sentence-BERT (arXiv:1908.10084)</td></tr>\n        <tr><td>Clustering</td><td>BERTopic (UMAP + HDBSCAN + c-TF-IDF)</td><td>arXiv:2203.05794</td></tr>\n        <tr><td>Visualization</td><td>UMAP 3D Projection</td><td>arXiv:1802.03426</td></tr>\n        <tr><td>Safety Routing</td><td>Entropy-based Multi-Agent Swarm</td><td>AAMAS 2026 (arXiv:2601.07006)</td></tr>\n        <tr><td>Cross-Modal Safety</td><td>Compositional Core (A-03)</td><td>arXiv:2602.10161</td></tr>\n        <tr><td>Cultural Context</td><td>Locale-Aware Routing (A-0.5)</td><td>NAACL 2025 (arXiv:2411.03888)</td></tr>\n        <tr><td>Governance</td><td>Adaptive Rubric Generation (A-10)</td><td>arXiv:2512.02530</td></tr>\n    </table>\n    \"\"\"\n)\n"
    }
  ]
}